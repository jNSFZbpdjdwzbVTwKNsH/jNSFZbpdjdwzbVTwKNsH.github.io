---
title: 15/10
layout: page
author: Carlo Rosso
date: 2025-10-15
---

1.  
    ```sh
    python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 3e-4 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 3e-5 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe --save-dir runs --seed 1
    ```

2. 
    ```sh
    uv run python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 3e-4 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe_tau5e-3 --save-dir runs --seed 1
    ```

    ```sh
    [Re-trained (soft weight sharing)] test acc: 0.9930
    [Quantized] test acc: 0.9081
    {
      "top1_error_pre[%]": 0.7800000000000029,
      "top1_error_post[%]": 9.189999999999998,
      "Delta[%]": 8.409999999999995,
      "|W|": 430500,
      "|W_nonzero|/|W|[%]": 66.62276422764228,
      "CR": 11.342659300305469,
      "acc_pretrain": 0.9922,
      "acc_retrain": 0.993,
      "acc_quantized": 0.9081
    }
    ```


3.
    ```sh
    uv run python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 5e-5 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe_tau5e-3_lr_5e-5 --save-dir runs --seed 1
    ```

4. With different mixture implementation

    ```sh
    uv run python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 5e-5 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe_tau5e-3_lr_5e-5_joseph_prior --save-dir runs --seed 1
    ```

5. With different mixture implementation, initial learning rate

    ```sh
    uv run python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 3e-4 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe_tau5e-3_lr_3e-4_joseph_prior --save-dir runs --seed 1
    ```
6. With different mixture implementation, initial learning rate

    ```sh
    uv run python run_sws.py --preset lenet5 \
      --pretrain-epochs 20 --retrain-epochs 30 \
      --pi0 0.95 --num-components 17 \
      --lr-w 5e-4 --lr-theta 5e-3 \
      --weight-decay 0.0 \
      --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
      --gamma-alpha 50 --gamma-beta 0.1 \
      --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
      --merge-kl-thresh 0.0 --quant-skip-last \
      --quant-assign ml \
      --log-mixture-every 1 --cr-every 5 \
      --run-name pt_lenet5_ml_safe_tau5e-3_lr_5e-3_joseph_prior --save-dir runs --seed 1
    ```


```sh
 scripts/tune_optuna.py \
  --preset wrn_16_4 \
  --n-trials 30 \
  --study-name sws_demo_lenet300100 \
  --storage sqlite:///sws_optuna.db \
  --sampler tpe \
  --save-dir runs \
  --max-acc-drop 0.5 \
  --penalty 25 \
  --timeout-sec 7200 \
  --keep-failed \
  --no-huffman \
  --quant-skip-last \
  --batch-size 128 \
  --num-workers 2 \
  --pretrain-epochs 0 \
  --retrain-epochs 100 \
  --lr-pre 1e-3 \
  --optim-pre adam \
  --eval-every 1 \
  --cr-every 10 \
  --seed 42 \
  --load-pretrained runs/pre_lenet300100/mnist_lenet_300_100_pre.pt
```

```
python scripts/inspect_assignments.py --run-dir <RUN_DIR>
```

---
```sh
uv run python run_sws.py --preset lenet5 \
    --pretrain-epochs 20 --retrain-epochs 30 \
    --pi0 0.95 --num-components 17 \
    --lr-w 5e-4 --lr-theta-means 1e-4 \
    --lr-theta-gammas 1e-4 \
    --lr-theta-rhos 1e-4 \
    --weight-decay 0.0 \
    --complexity-mode epoch --tau 5e-3 --tau-warmup-epochs 5 \
    --gamma-alpha 50 --gamma-beta 0.1 \
    --gamma-alpha-zero 100 --gamma-beta-zero 0.5 \
    --merge-kl-thresh 0.0 --quant-skip-last \
    --quant-assign ml \
    --log-mixture-every 1 --cr-every 5 \
    --run-name pt_lenet5_pre --save-dir runs --seed 1
```

Lenet 300 100

- 0
    compression: 11
    top1-error: 4.43

- 1
    compression: 5.50
    top1-error: 3.73

- 2
    compression: 7.2
    top1-error: 90

- 3
    compression: 0.4
    top1-error: 90

- 4
    compression: 7
    top1-error: 90

- 5
    compression: 11.20
    top1-error: 3.02

- 6
    compression: 11.69
    top1-error: 4.78

- 7
    compression: 9.90
    top1-error: 2.86

- 8
    compression: 8.88
    top1-error: 4.51

- 9
    compression: 11.25
    top1-error: 2.26


Considering the following command:

```py
python run_sws.py \
  --model lenet5 \
  --batch-size 128 \
  --num-workers 2 \
  --preset lenet_300_100 \
  --lr-pre 0.0005 \
  --optim-pre adam \
  --lr-w 0.0005 \
  --lr-theta-means 0.00011429388597024167 \
  --lr-theta-gammas 5.885634101391918e-05 \
  --lr-theta-rhos 6.422395404546397e-05 \
  --weight-decay 0.0 \
  --tau 0.0018293814886630763 \
  --tau-warmup-epochs 0 \
  --complexity-mode epoch \
  --auto-tau-ratio 0.0 \
  --num-components 17 \
  --pi0 0.9944924690724547 \
  --init-sigma 0.05640049212487919 \
  --init-means from_weights \
  --init-range-min -1 \
  --init-range-max 1 \
  --merge-kl-thresh 0.005781006887998078 \
  --gamma-alpha 152.6810443485974 \
  --gamma-beta 7.85381137217045 \
  --gamma-alpha-zero 288.18620544668215 \
  --gamma-beta-zero 65.15091032620245 \
  --run-name lenet5_baseline \
  --save-dir runs \
  --eval-every 1 \
  --cr-every 10 \
  --log-mixture-every 0 \
  --seed 22 \
  --no-huffman \
  --pbits-fc 5 \
  --pbits-conv 8 \
  --quant-skip-last \
  --quant-assign ml \
  --log-mixture-every 1 \
  --make-gif
```

can you swap in the following values?

```
  "dataset": "mnist",
  "model": "lenet5",
  "batch_size": 128,
  "num_workers": 2,
  "preset": "lenet5",
  "pretrain_epochs": 0,
  "lr_pre": 0.0005,
  "optim_pre": "adam",
  "load_pretrained": "runs/mnist_caffe/mnist_lenet5_pre.pt",
  "retrain_epochs": 30,
  "lr_w": 0.0005,
  "lr_theta_means": 6.19664167235096e-05,
  "lr_theta_gammas": 0.00020223799821007948,
  "lr_theta_rhos": 0.00018263122413799196,
  "weight_decay": 0.0,
  "tau": 0.0007302680313658672,
  "tau_warmup_epochs": 0,
  "complexity_mode": "epoch",
  "auto_tau_ratio": 0.0,
  "num_components": 17,
  "pi0": 0.9957972201507742,
  "init_sigma": 0.0729622587640403,
  "init_means": "from_weights",
  "init_range_min": -0.6,
  "init_range_max": 0.6,
  "merge_kl_thresh": 0.0109742968565678,
  "gamma_alpha": 218.7775074712217,
  "gamma_beta": 0.8871877192620952,
  "gamma_alpha_zero": 69.8947265017954,
  "gamma_beta_zero": 48.098981339609246,
  "beta_alpha": null,
  "beta_beta": null,
  "run_name": "lenet5_baseline",
  "save_dir": "runs",
  "eval_every": 1,
  "cr_every": 10,
  "log_mixture_every": 0,
  "seed": 14,
  "no_huffman": true,
  "pbits_fc": 5,
  "pbits_conv": 8,
  "quant_skip_last": true,
  "quant_assign": "ml",
```
python run_sws.py \
  --dataset mnist \
  --model lenet5 \
  --batch-size 128 \
  --num-workers 2 \
  --preset lenet5 \
  --lr-pre 0.0005 \
  --optim-pre adam \
  --lr-w 0.0005 \
  --lr-theta-means 6.19664167235096e-05 \
  --lr-theta-gammas 0.00020223799821007948 \
  --lr-theta-rhos 0.00018263122413799196 \
  --weight-decay 0.0 \
  --tau 0.0007302680313658672 \
  --tau-warmup-epochs 0 \
  --complexity-mode epoch \
  --auto-tau-ratio 0.0 \
  --num-components 17 \
  --pi0 0.9957972201507742 \
  --init-sigma 0.0729622587640403 \
  --init-means from_weights \
  --init-range-min -0.6 \
  --init-range-max 0.6 \
  --merge-kl-thresh 0.0109742968565678 \
  --gamma-alpha 218.7775074712217 \
  --gamma-beta 0.8871877192620952 \
  --gamma-alpha-zero 69.8947265017954 \
  --gamma-beta-zero 48.098981339609246 \
  --run-name lenet5_baseline \
  --save-dir runs \
  --eval-every 1 \
  --cr-every 10 \
  --log-mixture-every 0 \
  --seed 14 \
  --no-huffman \
  --pbits-fc 5 \
  --pbits-conv 8 \
  --quant-skip-last \
  --quant-assign ml \
  --make-gif

python run_sws.py \
    --preset wrn_16_4 \
    --run-name resnet_100 \
    --tau 5e-3 \
    --tau-warmup-epochs 0 \
    --quant-assign ml \
    --make-gif \
    --gif-fps 2 \
    --log-mixture-every 1 \
    --num-workers 2 \
    --retrain-epochs 100 \
    --seed 1 \
    --batch-size 128 \
    --init-range-min -1 \
    --init-range-max 1 \
    --gamma-alpha 218.7775074712217 \
    --gamma-beta 0.8871877192620952 \
    --gamma-alpha-zero 69.8947265017954 \
    --gamma-beta-zero 48.098981339609246 \

```py
python scripts/tune_optuna.py \
  --preset lenet_300_100 \
  --n-trials 50 \
  --study-name second_run \
  --sampler tpe \
  --save-dir runs/bayesian_optimization/lenet_300_100 \
  --max-acc-drop 10 \
  --penalty 25 \
  --timeout-sec 7200 \
  --keep-failed \
  --no-huffman \
  --quant-skip-last \
  --batch-size 128 \
  --num-workers 2 \
  --pretrain-epochs 0 \
  --retrain-epochs 40 \
  --lr-pre 5e-4 \
  --optim-pre adam \
  --eval-every 5 \
  --cr-every 10 \
  --seed 42 \
  --load-pretrained runs/mnist_300/mnist_lenet_300_100_pre.pt
```

```py
python scripts/tune_optuna.py \
  --preset lenet5 \
  --n-trials 50 \
  --study-name second_run \
  --sampler tpe \
  --save-dir runs/bayesian_optimization/lenet_5 \
  --max-acc-drop 10 \
  --penalty 25 \
  --timeout-sec 7200 \
  --keep-failed \
  --no-huffman \
  --quant-skip-last \
  --batch-size 128 \
  --num-workers 2 \
  --pretrain-epochs 0 \
  --retrain-epochs 40 \
  --lr-pre 5e-4 \
  --optim-pre adam \
  --eval-every 5 \
  --cr-every 10 \
  --seed 42 \
  --load-pretrained runs/mnist_caffe/mnist_lenet5_pre.pt
```
